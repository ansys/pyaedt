{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# HFSS: machine learning applied to a patch\nThis example shows how you can use PyAEDT to create a machine learning algorithm in three steps:\n\n#. Generate the database.\n#. Create the machine learning algorithm.\n#. Implement the model in a PyAEDT method.\n\nWhile this example supplies the code for all three steps in one Python file, it would be\nbetter to separate the code for each step into its own Python file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform required imports\nPerform required imports.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json\nimport os\nimport random\nfrom math import sqrt\n\nimport joblib\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\n\nfrom pyaedt import Hfss\nfrom pyaedt.modeler.advanced_cad.stackup_3d import Stackup3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set non-graphical mode\nSet non-graphical mode. ``\"PYAEDT_NON_GRAPHICAL\"`` is needed to generate\ndocumentation only.\nYou can set ``non_graphical`` either to ``True`` or ``False``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "non_graphical = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate database\nThis section describes the first step, which is for generating the database.\n\n## Generate input\nGenerate input randomly by creating a function with four inputs: frequency,\nsubstrate permittivity, substrate thickness, and patch width. Frequency ranges\nfrom 0.1 GHz to 1 GHz. Permittivity is from 1 to 12.\n\nThe following code generates a database of 1 frequency x 2 permittivity\nx 2 thickness x 2 width. It creates eight cases, which are far too few to\nuse to train the model but are a sufficient number for testing\nthe model. Later in this example, you import more than 3,300 different \ncases in a previously generated database of 74 frequencies\nx 5 permittivity x 3 thickness x 3 width.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tuple_random_frequency_permittivity = []\nfrequency_list = [150 * 1e6]\nfor in_list in frequency_list:\n    for i in range(2):\n        random_permittivity = 1 + 11 * int(random.random() * 100) / 100\n        temp_tuple = (in_list, random_permittivity)\n        tuple_random_frequency_permittivity.append(temp_tuple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thickness is generated from 0.0025 to 0.055 of the wavelength in the void.\nWidth is generated from 0.5 to 1.5 of the optimal theoretical width:\n\n``c / (2 * frequency * sqrt((permittivity + 1) / 2))``\n\nFor each couple of frequency-permittivity, three random thicknesses and three\nrandom widths are generated. Patch length is calculated using the analytic\nformula. Using this formula is important because it reduces the sweep\nfrequency needed for the data recovery. Every case is stored in a list of a\ndictionary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dictionary_list = []\nc = 2.99792458e8\nfor couple in tuple_random_frequency_permittivity:\n    list_thickness = []\n    list_width = []\n    frequency = couple[0]\n    permittivity = couple[1]\n    er = permittivity\n    wave_length_0 = c / frequency\n\n    min_thickness = 0.0025 * wave_length_0\n    inter_thickness = 0.01 * wave_length_0\n    max_thickness = 0.055 * wave_length_0\n    for i in range(2):\n        random_int = random.randint(0, 1)\n        if random_int == 0:\n            thickness = min_thickness + (inter_thickness - min_thickness) * random.random()\n        else:\n            thickness = inter_thickness + (max_thickness - inter_thickness) * random.random()\n        list_thickness.append(thickness)\n\n    min_width = 0.5 * c / (2 * frequency * sqrt((er + 1) / 2))\n    max_width = 1.5 * c / (2 * frequency * sqrt((er + 1) / 2))\n    for i in range(2):\n        width = min_width + (max_width - min_width) * random.random()\n        list_width.append(width)\n\n    for width in list_width:\n        for thickness in list_thickness:\n            effective_permittivity = (er + 1) / 2 + (er - 1) / (2 * sqrt(1 + 10 * thickness / width))\n            er_e = effective_permittivity\n            w_h = width / thickness\n            added_length = 0.412 * thickness * (er_e + 0.3) * (w_h + 0.264) / ((er_e - 0.258) * (w_h + 0.813))\n            wave_length = c / (frequency * sqrt(er_e))\n            length = wave_length / 2 - 2 * added_length\n            dictionary = {\n                \"frequency\": frequency,\n                \"permittivity\": permittivity,\n                \"thickness\": thickness,\n                \"width\": width,\n                \"length\": length,\n                \"previous_impedance\": 0,\n            }\n            dictionary_list.append(dictionary)\n\nprint(\"List of data: \" + str(dictionary_list))\nprint(\"Its length is: \" + str(len(dictionary_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate HFSS design\nGenerate the HFSS design using the ``Stackup3D`` method.\nOpen an HFSS design and create the stackup, add the different layers, and add\nthe patch. In the stackup library, most things, like the layers and patch,\nare already parametrized.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "desktopVersion = \"2023.1\"\n\nhfss = Hfss(\n    new_desktop_session=True, solution_type=\"Terminal\", non_graphical=non_graphical, specified_version=desktopVersion\n)\n\nstackup = Stackup3D(hfss)\nground = stackup.add_ground_layer(\"ground\", material=\"copper\", thickness=0.035, fill_material=\"air\")\ndielectric = stackup.add_dielectric_layer(\"dielectric\", thickness=10, material=\"Duroid (tm)\")\nsignal = stackup.add_signal_layer(\"signal\", material=\"copper\", thickness=0.035, fill_material=\"air\")\npatch = signal.add_patch(patch_length=1009.86, patch_width=1185.9, patch_name=\"Patch\", frequency=100e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resize layers around patch\nResize the layers around the patch so that they change when the patch changes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stackup.resize_around_element(patch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create lumped port\nCreate a lumped port that is parametrized with the function of the patch.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "patch.create_lumped_port(reference_layer=ground, opposite_side=False, port_name=\"one\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create line\nCreate a line that is parametrized with the function of the patch length. This\nensures that the air box is large enough in the normal direction of the patch.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "points_list = [\n    [patch.position_x.name, patch.position_y.name, signal.elevation.name],\n    [patch.position_x.name, patch.position_y.name, signal.elevation.name + \" + \" + patch.length.name],\n]\nhfss.modeler.create_polyline(position_list=points_list, name=\"adjust_airbox\")\npad_percent = [50, 50, 300, 50, 50, 10]\nregion = hfss.modeler.create_region(pad_percent)\nhfss.assign_radiation_boundary_to_objects(region)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot\nPlot patch\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hfss.plot(show=False, export_path=os.path.join(hfss.working_directory, \"Image.jpg\"), plot_air_objects=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create setup and sweep\nCreate a setup and a sweep by frequency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(len(dictionary_list))\nfor freq in frequency_list:\n    frequency_name = str(int(freq * 1e-6))\n    setup_name = \"Setup_\" + str(frequency_name)\n    current_setup = hfss.create_setup(setupname=setup_name)\n    current_setup.props[\"Frequency\"] = str(freq) + \"Hz\"\n    current_setup.props[\"MaximumPasses\"] = 30\n    current_setup.props[\"MinimumConvergedPasses\"] = 2\n    current_setup.props[\"MaxDeltaS\"] = 0.05\n    current_setup.update()\n    current_setup[\"SaveAnyFields\"] = False\n\n    freq_start = freq * 0.75\n    freq_stop = freq * 1.25\n    sweep_name = \"Sweep_of_\" + setup_name\n    hfss.create_linear_count_sweep(\n        setupname=setup_name,\n        unit=\"Hz\",\n        freqstart=freq_start,\n        freqstop=freq_stop,\n        num_of_freq_points=25000,\n        sweepname=\"Sweep_of_\" + setup_name,\n        save_fields=False,\n        sweep_type=\"Interpolating\",\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define function\nDefine a function to recover the index of the resonance frequency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def index_of_resonance(imaginary_list, real_list):\n    list_of_index = []\n    for i in range(1, len(imaginary_list)):\n        if imaginary_list[i] * imaginary_list[i - 1] < 0:\n            if abs(imaginary_list[i]) < abs(imaginary_list[i - 1]):\n                list_of_index.append(i)\n            elif abs(imaginary_list[i]) > abs(imaginary_list[i - 1]):\n                list_of_index.append(i - 1)\n    if len(list_of_index) == 0:\n        return 0\n    elif len(list_of_index) == 1:\n        return list_of_index[0]\n    else:\n        storage = 0\n        resonance_index = 0\n        for index in list_of_index:\n            if storage < real_list[index]:\n                storage = real_list[index]\n                resonance_index = index\n        return resonance_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create parametric variation by case\nUse a loop to create a parametric variation by case and associate it with a setup.\nThe parametric variation is composed of the patch length and width and substrate\npermittivity and thickness. For each, measure the real resonance frequency to\nobtain the data length, width, permittivity, and thickness that corresponds\nto a resonance frequency. Use an error counter to verify that the resonance\nfrequency is contained in the sweep. To make it easy, calculate the length\nof each case using the analytic formula.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "error_counter = []\nfor i in range(len(dictionary_list)):\n    dictio = dictionary_list[i]\n    frequency_name = str(int(dictio[\"frequency\"] * 1e-6))\n    setup_name = \"Setup_\" + str(frequency_name)\n    sweep_name = \"Sweep_of_\" + setup_name\n    length_variation = dictio[\"length\"] * 1e3\n    width_variation = dictio[\"width\"] * 1e3\n    thickness_variation = dictio[\"thickness\"] * 1e3\n    permittivity_variation = dictio[\"permittivity\"]\n    param_name = \"para_\" + setup_name + \"_\" + str(i)\n    this_param = hfss.parametrics.add(\n        patch.length.name,\n        length_variation,\n        length_variation,\n        step=1,\n        variation_type=\"LinearCount\",\n        solution=setup_name,\n        parametricname=param_name,\n    )\n    this_param.add_variation(\n        patch.width.name, width_variation, width_variation, step=1, unit=None, variation_type=\"LinearCount\"\n    )\n    this_param.add_variation(\n        dielectric.thickness.name,\n        thickness_variation,\n        thickness_variation,\n        step=1,\n        unit=None,\n        variation_type=\"LinearCount\",\n    )\n    this_param.add_variation(\n        \"$cloned_Duroid__tm__permittivity\",\n        permittivity_variation,\n        permittivity_variation,\n        step=1,\n        unit=None,\n        variation_type=\"LinearCount\",\n    )\n    hfss.analyze_setup(param_name, num_cores=4, num_tasks=None)\n    data = hfss.post.get_solution_data(\n        \"Zt(one_T1, one_T1)\",\n        setup_sweep_name=setup_name + \" : \" + sweep_name,\n        domain=\"Sweep\",\n        variations={\n            patch.length.name: [str(length_variation) + \"mm\"],\n            patch.width.name: [str(width_variation) + \"mm\"],\n            dielectric.thickness.name: [str(thickness_variation) + \"mm\"],\n            \"$cloned_Duroid__tm__permittivity\": [str(permittivity_variation)],\n        },\n        polyline_points=25000,\n    )\n    imaginary_part = data.data_imag()\n    real_part = data.data_real()\n    corresponding_index = index_of_resonance(imaginary_part, real_part)\n    if corresponding_index == 0:\n        hfss.logger.error(\"The resonance is out of the range\")\n        error_counter.append(i)\n    minimum_imaginary = imaginary_part[corresponding_index]\n    previous_impedance = real_part[corresponding_index]\n    print(\"minimum_imaginary: \" + str(minimum_imaginary))\n    print(\"previous_impedance: \" + str(previous_impedance))\n    frequency_list = data.primary_sweep_values\n    resonance_frequency = frequency_list[corresponding_index]\n    print(resonance_frequency)\n    dictio[\"frequency\"] = resonance_frequency\n    dictio[\"previous_impedance\"] = previous_impedance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print error\nPrint the number of range error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"number of range error: \" + str(error_counter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End data recovery step\nEnd the data recovery step by dumping the dictionary list into a JSON file.\nSaving the data allows you to use it in another Python script.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "json_file_path = os.path.join(hfss.working_directory, \"ml_data_for_test.json\")\nwith open(json_file_path, \"w\") as readfile:\n    json.dump(dictionary_list, readfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create machine learning algorithm\nThis section describes the second step, which is for creating the machine\nlearning algorithm.\n\n## Import training cases\nImport the 3,300 cases in the supplied JSON file to train the model. As mentioned\nearlier, you cannot use the small database that you generated earlier for training\nthe model. Its 8 cases are used later to test the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path_folder = hfss.pyaedt_dir\ntraining_file = os.path.join(path_folder, \"misc\", \"ml_data_file_train_100MHz_1GHz.json\")\nwith open(training_file) as readfile:\n    my_dictio_list_train = json.load(readfile)\n\nwith open(json_file_path, \"r\") as readfile:\n    my_dictio_list_test = json.load(readfile)\n\nprint(len(my_dictio_list_train))\nprint(len(my_dictio_list_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create lists\nCreate four lists:\n\n- One for the input of the training\n- One for the output of training\n- Oone for the input of the test\n- One for the output of the test\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_for_training_list = []\noutput_for_training_list = []\ninput_for_test_list = []\noutput_for_test_list = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fill list for input of training\nFill the list for the input of the training with frequency, width, permittivity,\nand thickness so that the output is the length. The objective of this\nalgorithm is to predict the length according to the rest.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i in range(len(my_dictio_list_train)):\n    freq_width_perm_thick = [\n        my_dictio_list_train[i][\"frequency\"] * 1e9,\n        my_dictio_list_train[i][\"width\"] * 1000,\n        my_dictio_list_train[i][\"permittivity\"],\n        my_dictio_list_train[i][\"thickness\"] * 1000,\n    ]\n    length = my_dictio_list_train[i][\"length\"] * 1000\n    input_for_training_list.append(freq_width_perm_thick)\n    output_for_training_list.append(length)\n\nfor i in range(len(my_dictio_list_test)):\n    freq_width_perm_thick = [\n        my_dictio_list_test[i][\"frequency\"] * 1e9,\n        my_dictio_list_test[i][\"width\"] * 1000,\n        my_dictio_list_test[i][\"permittivity\"],\n        my_dictio_list_test[i][\"thickness\"] * 1000,\n    ]\n    length = my_dictio_list_test[i][\"length\"] * 1000\n    input_for_test_list.append(freq_width_perm_thick)\n    output_for_test_list.append(length)\n\nprint(\"number of test cases: \" + str(len(output_for_test_list)))\nprint(\"number of training cases: \" + str(len(output_for_training_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert lists in array\nConvert the lists in an array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_for_training_array = np.array(input_for_training_list, dtype=np.float32)\noutput_for_training_array = np.array(output_for_training_list, dtype=np.float32)\ninput_for_test_array = np.array(input_for_test_list, dtype=np.float32)\noutput_for_test_array = np.array(output_for_test_list, dtype=np.float32)\n\nprint(\"input array for training: \" + str(input_for_training_array))\nprint(\"output array for training: \" + str(output_for_training_array))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create model\nCreate the model. Depending on the app, you can use different models.\nThe easiest way to find the correct model for an app is to search\nfor this app or one that is close to it.\n\nTo predict characteristics of a patch antenna (resonance frequency, bandwidth,\nand input impedance), you can use SVR (Support Vector Regression) or ANN\n(Analyze Neuronal Network). The following code uses SVR because it is easier\nto implement. ANN is a more general method that also works with other\nhigh frequency components. While it is more likely to work for other app,\nimplementing ANN is much more complex.\n\nFor SVR, there are three different kernels. For the patch antenna, RBF (Radial Basic\nFunction) is preferred. There are three other arguments that have a big impact\non the accuracy of the model: C, gamma, and epsilon. Sometimes they are given\nwith the necessary model for the app. Otherwise, you can try different\nvalues and see which one is the best by measuring the accuracy of the model.\nTo make this example shorter, ``C=1e4``. However, the optimal value\nin this app is ``C=5e4``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "svr_rbf = SVR(kernel=\"rbf\", C=1e4, gamma=\"auto\", epsilon=0.05)\nregression = make_pipeline(StandardScaler(), svr_rbf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train model\nTrain the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regression.fit(input_for_training_array, output_for_training_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dump model into JOBLIB file\nDump the model into a JOBLIB file using the same method as you used earlier\nfor the JSON file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_file = os.path.join(hfss.working_directory, \"svr_model.joblib\")\njoblib.dump(regression, model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implement model in PyAEDT method\nThis section describes the third step, which is for implementing the model\nin the PyAEDT method.\n\n## Load model\nLoad the model in another Python file to predict different cases.\nHere the correct model with ``C=5e4`` is loaded rather than the one you made\nearlier with ``C=1e4``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(path_folder, \"misc\", \"patch_svr_model_100MHz_1GHz.joblib\")\nregression = joblib.load(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict length of patch\nPredict the length of the patch as a function of its resonant frequency and width\nand substrate thickness and permittivity.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prediction_of_length = regression.predict(input_for_test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measure model efficiency\nMeasure the model efficiency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "average_relative_gap = 0\ncounter_under_zero_five = 0\ncounter_under_one = 0\ncounter_under_two = 0\ncounter_under_five = 0\ncounter_under_ten = 0\ncounter_upper_ten = 0\nrel_counter_under_one = 0\nrel_counter_under_two = 0\nrel_counter_under_five = 0\nrel_counter_under_ten = 0\nrel_counter_under_twenty = 0\nrel_counter_upper_twenty = 0\nfor index in range(len(prediction_of_length)):\n    print(\n        \"value: \"\n        + str(input_for_test_list[index])\n        + \", prediction: \"\n        + str(prediction_of_length[index] * 1000)\n        + \", reality: \"\n        + str(output_for_test_list[index] * 1000)\n    )\n    gap = abs(prediction_of_length[index] - output_for_test_list[index])\n    relative_gap = gap / output_for_test_list[index]\n    average_relative_gap = average_relative_gap + relative_gap\n    if gap < 0.5:\n        counter_under_zero_five += 1\n    elif 0.5 <= gap < 1:\n        counter_under_one += 1\n    elif 1 <= gap < 2:\n        counter_under_two += 1\n    elif 2 <= gap < 5:\n        counter_under_five += 1\n    elif 5 <= gap < 10:\n        counter_under_ten += 1\n    else:\n        counter_upper_ten += 1\n    if relative_gap < 0.01:\n        rel_counter_under_one += 1\n    elif relative_gap < 0.02:\n        rel_counter_under_two += 1\n    elif relative_gap < 0.05:\n        rel_counter_under_five += 1\n    elif relative_gap < 0.1:\n        rel_counter_under_ten += 1\n    elif relative_gap < 0.2:\n        rel_counter_under_twenty += 1\n    else:\n        rel_counter_upper_twenty += 1\naverage_relative_gap = average_relative_gap / len(prediction_of_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first displays are the gap ``(prediction - real)``. The second displays are\nthe relative gap ``((prediction - real)/real)``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"sample size: \" + str(len(prediction_of_length)))\nprint(\"<0.5 : \" + str(counter_under_zero_five))\nprint(\"<1 : \" + str(counter_under_one))\nprint(\"<2 : \" + str(counter_under_two))\nprint(\"<5 : \" + str(counter_under_five))\nprint(\"<10 : \" + str(counter_under_ten))\nprint(\">10 : \" + str(counter_upper_ten) + \"\\n\")\nprint(\n    \"sum : \"\n    + str(\n        counter_under_zero_five\n        + counter_under_one\n        + counter_under_two\n        + counter_under_five\n        + counter_under_ten\n        + counter_upper_ten\n    )\n)\n\nprint(\"-------------------------------------------\\n\")\nprint(\"<0.01 : \" + str(rel_counter_under_one))\nprint(\"<0.02 : \" + str(rel_counter_under_two))\nprint(\"<0.05 : \" + str(rel_counter_under_five))\nprint(\"<0.1 : \" + str(rel_counter_under_ten))\nprint(\"<0.2 : \" + str(rel_counter_under_twenty))\nprint(\">0.2 : \" + str(rel_counter_upper_twenty))\nprint(\n    \"sum : \"\n    + str(\n        rel_counter_under_one\n        + rel_counter_under_two\n        + rel_counter_under_five\n        + rel_counter_under_ten\n        + rel_counter_under_twenty\n        + rel_counter_upper_twenty\n    )\n)\nprint(\"average is : \" + str(average_relative_gap))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Release AEDT\nRelease AEDT.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hfss.release_desktop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}